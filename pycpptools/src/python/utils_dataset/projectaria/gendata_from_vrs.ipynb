{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data with the general dataset from VRS \n",
    "Format of general dataset\n",
    "```\n",
    "ucl_east/\n",
    "    seq/\n",
    "        000000.color.png\n",
    "        000000.depth.png (mm)\n",
    "        000000.semantic.png (optional)\n",
    "    poses.txt (TUM format: timestamp tx ty tz qx qy qz qw)\n",
    "    intrinsics.txt (format: fx fy cx cy width height)\n",
    "    gps.txt (format: timestamp, latitude, longitude, altitude, speed, accuracy)\n",
    "```\n",
    "\n",
    "#### Pipeline:\n",
    "1. Load the VRS file\n",
    "2. Load the MPS trajectory\n",
    "3. Read through all images\n",
    "4. For each image, find the nearest pose of the image, compute the pose of the camera, rotate image, and save\n",
    "5. Save poses, intrinsics, and gps to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from projectaria_tools.core import data_provider, calibration\n",
    "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
    "from projectaria_tools.core.stream_id import RecordableTypeId, StreamId\n",
    "from projectaria_tools.core.mps.utils import get_nearest_pose\n",
    "import projectaria_tools.core.mps as mps\n",
    "from projectaria_tools.core.sophus import SO3, SE3, interpolate, iterativeMean\n",
    "import numpy as np\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "data_path = \"/Rocket_ssd/dataset/data_litevloc/ucl_campus/map_multisession_eval/raw_vrs\"\n",
    "# Input data\n",
    "vrsfile = os.path.join(data_path, \"ucl_campus_20241128_1103.vrs\")\n",
    "open_traj_file = os.path.join(data_path, \"ucl_campus_multiagent_20241128/1/slam/open_loop_trajectory.csv\")\n",
    "closed_traj_file = os.path.join(data_path, \"ucl_campus_multiagent_20241128/1/slam/closed_loop_trajectory.csv\")\n",
    "# Output data\n",
    "out_dir = os.path.join(data_path, \"out_general_ucl_campus_20241128_1103\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(out_dir, \"seq\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VRS file\n",
    "provider = data_provider.create_vrs_data_provider(vrsfile)\n",
    "assert provider is not None, \"Cannot open file\"\n",
    "# Load trajectories\n",
    "open_loop_traj = mps.read_open_loop_trajectory(open_traj_file)\n",
    "closed_loop_traj = mps.read_closed_loop_trajectory(closed_traj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(gogojjh): not used\n",
    "# import cv2\n",
    "# image_path = os.path.join(data_path, \"obs_image_example.png\")\n",
    "# ref_img = cv2.imread(image_path)\n",
    "# ref_img_lab = cv2.cvtColor(ref_img, cv2.COLOR_BGR2LAB)\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.imshow(ref_img, cmap='gray', vmin=0, vmax=255)\n",
    "# plt.title(\"Reference image\")\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(gogojjh): not used\n",
    "def reduce_image_domain_gap(tar_img, domain_unified_flag=False):\n",
    "    if domain_unified_flag:\n",
    "#         import cv2\n",
    "#         import numpy as np\n",
    "#         from skimage import exposure\n",
    "\n",
    "#         tar_img_lab = cv2.cvtColor(tar_img, cv2.COLOR_BGR2LAB)\n",
    "#         tar_matched = np.empty_like(tar_img_lab)\n",
    "#         for i in range(3):\n",
    "#             tar_matched[:, :, i] = exposure.match_histograms(tar_img_lab[:, :, i], ref_img_lab[:, :, i])\n",
    "#         tar_matched_bgr = cv2.cvtColor(tar_matched, cv2.COLOR_LAB2BGR)\n",
    "#         return tar_matched_bgr\n",
    "        return tar_img\n",
    "    else:\n",
    "        return tar_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE(gogojjh): helper function\n",
    "valid_functions = []\n",
    "for key in dir(provider):\n",
    "    if \"__\" not in key:\n",
    "        valid_functions.append(key)\n",
    "print(valid_functions)\n",
    "\n",
    "print(\"Show all streams and sensors:\")\n",
    "streams = provider.get_all_streams()\n",
    "for stream_id in streams:\n",
    "    label = provider.get_label_from_stream_id(stream_id)\n",
    "    print(\n",
    "        f\"stream_id: [{stream_id}] convert to label: [{label}] and back: [{provider.get_stream_id_from_label(label)}]\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the GPS data\n",
    "stream_id = provider.get_stream_id_from_label(\"gps\")\n",
    "num_data = provider.get_num_data(stream_id)\n",
    "latitude, longitude, altitude, accuracy, speed, timestamps = [], [], [], [], [], []\n",
    "for index in range(0, num_data):\n",
    "  gps_data = provider.get_gps_data_by_index(stream_id, index)\n",
    "  latitude.append(gps_data.latitude)\n",
    "  longitude.append(gps_data.longitude)\n",
    "  altitude.append(gps_data.altitude)\n",
    "  accuracy.append(gps_data.accuracy)\n",
    "  speed.append(gps_data.speed)\n",
    "  timestamps.append(gps_data.capture_timestamp_ns * 1e-9)\n",
    "\n",
    "# Test\n",
    "gps_data = provider.get_gps_data_by_index(stream_id, num_data - 100)\n",
    "print(f\"GPS data: {gps_data.latitude}, {gps_data.longitude}, {gps_data.altitude}, {gps_data.speed}, {gps_data.capture_timestamp_ns}\")\n",
    "query_timestamp = gps_data.capture_timestamp_ns\n",
    "gps_data = provider.get_gps_data_by_time_ns(stream_id, query_timestamp,  TimeDomain.DEVICE_TIME)\n",
    "print(f\"GPS data: {gps_data.latitude}, {gps_data.longitude}, {gps_data.altitude}, {gps_data.speed}, {gps_data.capture_timestamp_ns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_debug = False\n",
    "# Initialize parameters\n",
    "poses = np.zeros((0, 8))      # timestamp, tx, ty, tz, qw, qx, qy, qz\n",
    "intrinsics = np.zeros((0, 6)) # fx, fy, cx, cy, width, height\n",
    "gps_data = np.zeros((0, 6))   # timestamp, lat, lon, alt, speed, accuracy\n",
    "img_save_idx = 0\n",
    "# Set a initial pose\n",
    "T_ini = SE3().from_matrix(np.eye(4, 4))\n",
    "init_pose = False\n",
    "# Load image\n",
    "camera_label = \"camera-rgb\"; camera_stream_id = provider.get_stream_id_from_label(camera_label)\n",
    "camera_num_data = provider.get_num_data(camera_stream_id)\n",
    "print(f\"Stream ID (camera): {camera_stream_id} with {camera_num_data} data\")\n",
    "# Load GPS\n",
    "gps_label = \"gps\"; gps_stream_id = provider.get_stream_id_from_label(gps_label)\n",
    "gps_num_data = provider.get_num_data(gps_stream_id)\n",
    "print(f\"Stream ID (gps): {gps_stream_id} with {gps_num_data} data\")\n",
    "for index in range(0, camera_num_data):\n",
    "# for index in range(0, 10):\n",
    "    ##### Get image data\n",
    "    img_data = provider.get_image_data_by_index(camera_stream_id, index)\n",
    "    img_timestamp = img_data[1].capture_timestamp_ns\n",
    "    # print(f\"Get image data at index {index} with timestamp {img_timestamp}\")\n",
    "\n",
    "    raw_calib = provider.get_device_calibration().get_camera_calib(camera_label)\n",
    "    focal_length = raw_calib.get_focal_lengths()\n",
    "    principal_point = raw_calib.get_principal_point()\n",
    "    image_size = raw_calib.get_image_size() # width, height\n",
    "    \n",
    "    ##### Option 1: use the raw image size\n",
    "    # pinhole = calibration.get_linear_camera_calibration(\n",
    "    #     image_size[0], image_size[1], focal_length[0], camera_label, raw_calib.get_transform_device_camera())\n",
    "    ##### Option 2: use the specific image size\n",
    "    pinhole = calibration.get_linear_camera_calibration(\n",
    "        576, 1024, focal_length[0] * (1024 / image_size[0]), camera_label, raw_calib.get_transform_device_camera()) # height, width\n",
    "    raw_image = img_data[0].to_numpy_array()\n",
    "    undistorted_image = calibration.distort_by_calibration(raw_image, pinhole, raw_calib)\n",
    "    \n",
    "    rotated_image = np.rot90(undistorted_image, k=3)\n",
    "    pinhole_cw90 = calibration.rotate_camera_calib_cw90deg(pinhole)\n",
    "    focal_length = pinhole_cw90.get_focal_lengths()\n",
    "    principal_point = pinhole_cw90.get_principal_point()\n",
    "    image_size = pinhole_cw90.get_image_size()\n",
    "\n",
    "    if flag_debug:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(raw_image, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(\"Raw image\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(undistorted_image, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(\"Undistorted image\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(rotated_image, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(\"Rotated image\")\n",
    "        plt.axis('off')\n",
    "        plt.show()        \n",
    "\n",
    "    ##### Get GPS data\n",
    "    data = provider.get_gps_data_by_time_ns(gps_stream_id, img_timestamp, TimeDomain.DEVICE_TIME)\n",
    "    if data.accuracy > 1e3 or data.accuracy < 1e-9:\n",
    "        # Not valid GPS data\n",
    "        vec = np.array([img_timestamp/1e9, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "    else:\n",
    "        vec = np.array([img_timestamp/1e9, data.latitude, data.longitude, data.altitude, data.speed, data.accuracy])\n",
    "    gps_data = np.vstack((gps_data, vec))\n",
    "\n",
    "    ##### Get pose data\n",
    "    pose_info = get_nearest_pose(closed_loop_traj, img_timestamp)\n",
    "    if pose_info:\n",
    "        T_world_device = pose_info.transform_world_device\n",
    "        T_device_rgb_camera = pinhole_cw90.get_transform_device_camera()\n",
    "        T_world_rgb_camera = T_world_device @ T_device_rgb_camera\n",
    "        if not init_pose:\n",
    "            ##### Option 1: set the z-axis of the world frame same to gravity direction\n",
    "            # T_gravity_camera = SE3().from_matrix3x4(np.array([0, 0, 1, 0, -1, 0, 0, 0, 0, -1, 0, 0]).reshape(3, 4))\n",
    "            ##### Option 2: set the world frame as the camera frame\n",
    "            T_gravity_camera = SE3().from_matrix(np.eye(4, 4))\n",
    "\n",
    "            # reset the camera pose at zero\n",
    "            T_cam_reset = T_world_rgb_camera.inverse()\n",
    "\n",
    "            # Compose the transformation\n",
    "            T_offset = T_gravity_camera @ T_cam_reset\n",
    "            \n",
    "            init_pose = True\n",
    "        T_world_rgb_camera_rgb_camera = T_offset @ T_world_rgb_camera\n",
    "\n",
    "        vec = T_world_rgb_camera_rgb_camera.to_quat_and_translation()\n",
    "        quat_wxyz, trans = vec[0, :4], vec[0, 4:]\n",
    "        pose = np.array([img_timestamp/1e9, \n",
    "                         trans[0], trans[1], trans[2], \n",
    "                         quat_wxyz[1], quat_wxyz[2], quat_wxyz[3], quat_wxyz[0]])\n",
    "        poses = np.vstack((poses, pose))\n",
    "        intrinsic = np.array([focal_length[0], focal_length[1], \n",
    "                              principal_point[0], principal_point[1], \n",
    "                              image_size[0], image_size[1]])\n",
    "        intrinsics = np.vstack((intrinsics, intrinsic))\n",
    "        \n",
    "        processed_img = reduce_image_domain_gap(rotated_image, domain_unified_flag=False)\n",
    "        image_pil = Image.fromarray(processed_img.astype(np.uint8))\n",
    "        image_pil.save(os.path.join(out_dir, \"seq\", f\"{img_save_idx:06d}.color.jpg\"))\n",
    "        if img_save_idx % 100 == 0: print(f\"Save image {img_save_idx:06d}.color.jpg\")\n",
    "        img_save_idx += 1\n",
    "\n",
    "np.savetxt(os.path.join(out_dir, \"poses.txt\"), poses, fmt='%.6f')\n",
    "np.savetxt(os.path.join(out_dir, \"intrinsics.txt\"), intrinsics, fmt='%.6f ' * 4 + '%d %d')\n",
    "np.savetxt(os.path.join(out_dir, \"gps_data.txt\"), gps_data, fmt='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(poses[:, 1], poses[:, 3], '-')\n",
    "plt.title('X-Z Curve')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Z')\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectaria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
