{
      "cells": [
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### Generate data with the general dataset from VRS \n",
                        "Format of general dataset\n",
                        "```\n",
                        "ucl_east/\n",
                        "    seq/\n",
                        "        000000.color.png\n",
                        "        000000.depth.png (mm)\n",
                        "        000000.semantic.png (optional)\n",
                        "    poses.txt (TUM format: timestamp tx ty tz qx qy qz qw)\n",
                        "    intrinsics.txt (format: fx fy cx cy width height)\n",
                        "    gps.txt (format: timestamp, latitude, longitude, altitude, speed, accuracy)\n",
                        "```\n",
                        "\n",
                        "#### Pipeline:\n",
                        "1. Load the VRS file\n",
                        "2. Load the MPS trajectory\n",
                        "3. Read through all images\n",
                        "4. For each image, find the nearest pose of the image, compute the pose of the camera, rotate image, and save\n",
                        "5. Save poses, intrinsics, and gps to files"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import os\n",
                        "from projectaria_tools.core import data_provider, calibration\n",
                        "from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions\n",
                        "from projectaria_tools.core.stream_id import RecordableTypeId, StreamId\n",
                        "from projectaria_tools.core.mps.utils import get_nearest_pose\n",
                        "import projectaria_tools.core.mps as mps\n",
                        "from projectaria_tools.core.sophus import SO3, SE3, interpolate, iterativeMean\n",
                        "import numpy as np\n",
                        "import copy\n",
                        "from PIL import Image\n",
                        "from matplotlib import pyplot as plt\n",
                        "import json"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "\"\"\" \n",
                        "Single-session\n",
                        "\"\"\"\n",
                        "# vrs_data_path = \"/Rocket_ssd/dataset/data_richmond\"\n",
                        "# out_data_path = \"/Rocket_ssd/dataset/data_richmond\"\n",
                        "# session_path = os.path.join(vrs_data_path, 'mps_Richmond_forest_01_vrs')\n",
                        "# vrs_name = 'Richmond_forest_01.vrs'\n",
                        "\n",
                        "# # Input data\n",
                        "# vrsfile = os.path.join(vrs_data_path, vrs_name)\n",
                        "# open_traj_file = os.path.join(session_path, f\"slam/open_loop_trajectory.csv\")\n",
                        "# closed_traj_file = os.path.join(session_path, f\"slam/closed_loop_trajectory.csv\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "\"\"\" \n",
                        "Multi-session\n",
                        "\"\"\"\n",
                        "##### Multi-session \n",
                        "vrs_data_path = \"/Rocket_ssd/dataset/data_litevloc/map_multisession_eval/raw_vrs/ucl_campus\"\n",
                        "out_data_path = \"/Rocket_ssd/dataset/data_litevloc/map_multisession_eval/raw_vrs/ucl_campus\"\n",
                        "session_path = os.path.join(vrs_data_path, 'ucl_campus_multiagent_20241205_1017_24sessions')\n",
                        "json_vrs_to_session_path = os.path.join(session_path, 'vrs_to_multi_slam.json')\n",
                        "vrs_name = 'ucl_campus_20241127_1716.vrs'\n",
                        "\n",
                        "# Input data\n",
                        "with open(json_vrs_to_session_path, 'r', encoding='utf-8') as file:\n",
                        "    data_vrs_to_session = json.load(file)\n",
                        "vrsfile = os.path.join(vrs_data_path, \"vrs_withrgb\", vrs_name)\n",
                        "session_id = data_vrs_to_session[f\"vrs_norgb_seq0/{vrs_name}\"]\n",
                        "# Relative world coordinate of open_loop_trajectory\n",
                        "open_traj_file = os.path.join(session_path, f\"{session_id}/slam/open_loop_trajectory.csv\")\n",
                        "# Absolute world coordinate of closed_loop_trajectory\n",
                        "closed_traj_file = os.path.join(session_path, f\"{session_id}/slam/closed_loop_trajectory.csv\")\n",
                        "\n",
                        "# Output data\n",
                        "out_dir = os.path.join(out_data_path, f\"out_general_{vrs_name.split('.')[0]}\")\n",
                        "os.makedirs(out_dir, exist_ok=True)\n",
                        "os.makedirs(os.path.join(out_dir, \"seq\"), exist_ok=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Load VRS file\n",
                        "provider = data_provider.create_vrs_data_provider(vrsfile)\n",
                        "assert provider is not None, \"Cannot open file\"\n",
                        "# Load trajectories\n",
                        "# Definition of open-loop (VIO) and closed-loop (bundle adjustment) trajectory:\n",
                        "#   https://facebookresearch.github.io/projectaria_tools/docs/data_formats/mps/slam/mps_trajectory#open-loop-trajectory\n",
                        "open_loop_traj = mps.read_open_loop_trajectory(open_traj_file)\n",
                        "closed_loop_traj = mps.read_closed_loop_trajectory(closed_traj_file)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# NOTE(gogojjh): not used\n",
                        "# import cv2\n",
                        "# image_path = os.path.join(data_path, \"obs_image_example.png\")\n",
                        "# ref_img = cv2.imread(image_path)\n",
                        "# ref_img_lab = cv2.cvtColor(ref_img, cv2.COLOR_BGR2LAB)\n",
                        "# plt.figure(figsize=(5,5))\n",
                        "# plt.imshow(ref_img, cmap='gray', vmin=0, vmax=255)\n",
                        "# plt.title(\"Reference image\")\n",
                        "# plt.axis('off')"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# NOTE(gogojjh): not used\n",
                        "def reduce_image_domain_gap(tar_img, domain_unified_flag=False):\n",
                        "    if domain_unified_flag:\n",
                        "#         import cv2\n",
                        "#         import numpy as np\n",
                        "#         from skimage import exposure\n",
                        "\n",
                        "#         tar_img_lab = cv2.cvtColor(tar_img, cv2.COLOR_BGR2LAB)\n",
                        "#         tar_matched = np.empty_like(tar_img_lab)\n",
                        "#         for i in range(3):\n",
                        "#             tar_matched[:, :, i] = exposure.match_histograms(tar_img_lab[:, :, i], ref_img_lab[:, :, i])\n",
                        "#         tar_matched_bgr = cv2.cvtColor(tar_matched, cv2.COLOR_LAB2BGR)\n",
                        "#         return tar_matched_bgr\n",
                        "        return tar_img\n",
                        "    else:\n",
                        "        return tar_img"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# NOTE(gogojjh): helper function\n",
                        "valid_functions = []\n",
                        "for key in dir(provider):\n",
                        "    if \"__\" not in key:\n",
                        "        valid_functions.append(key)\n",
                        "print(valid_functions)\n",
                        "\n",
                        "print(\"Show all streams and sensors:\")\n",
                        "streams = provider.get_all_streams()\n",
                        "for stream_id in streams:\n",
                        "    label = provider.get_label_from_stream_id(stream_id)\n",
                        "    print(\n",
                        "        f\"stream_id: [{stream_id}] convert to label: [{label}] and back: [{provider.get_stream_id_from_label(label)}]\"\n",
                        "    )"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Read the GPS data\n",
                        "stream_id = provider.get_stream_id_from_label(\"gps\")\n",
                        "num_data = provider.get_num_data(stream_id)\n",
                        "latitude, longitude, altitude, accuracy, speed, timestamps = [], [], [], [], [], []\n",
                        "for index in range(0, num_data):\n",
                        "  gps_data = provider.get_gps_data_by_index(stream_id, index)\n",
                        "  latitude.append(gps_data.latitude)\n",
                        "  longitude.append(gps_data.longitude)\n",
                        "  altitude.append(gps_data.altitude)\n",
                        "  accuracy.append(gps_data.accuracy)\n",
                        "  speed.append(gps_data.speed)\n",
                        "  timestamps.append(gps_data.capture_timestamp_ns * 1e-9)\n",
                        "\n",
                        "# Test\n",
                        "gps_data = provider.get_gps_data_by_index(stream_id, num_data - 100)\n",
                        "print(f\"GPS data: {gps_data.latitude}, {gps_data.longitude}, {gps_data.altitude}, {gps_data.speed}, {gps_data.capture_timestamp_ns}\")\n",
                        "query_timestamp = gps_data.capture_timestamp_ns\n",
                        "gps_data = provider.get_gps_data_by_time_ns(stream_id, query_timestamp,  TimeDomain.DEVICE_TIME)\n",
                        "print(f\"GPS data: {gps_data.latitude}, {gps_data.longitude}, {gps_data.altitude}, {gps_data.speed}, {gps_data.capture_timestamp_ns}\")\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# DEBUG(gogojjh): check the pose data\n",
                        "# print(f\"Image device timestamp: {img_timestamp / 1e9}\")\n",
                        "# print(f\"Open Pose device timestamp: {pose_info_open.tracking_timestamp.total_seconds()}\")\n",
                        "# print(f\"Open Pose utc timestamp: {pose_info_open.utc_timestamp}\")\n",
                        "# print(f\"Closed Pose device timestamp: {pose_info_closed.tracking_timestamp.total_seconds()}\")\n",
                        "# print(f\"Closed Pose utc timestamp: {pose_info_closed.utc_timestamp}\")\n",
                        "# print(f\"{pose_info_open.utc_timestamp.total_seconds():.6f}\")\n",
                        "# print(f\"{pose_info_closed.utc_timestamp.total_seconds():.6f}\")\n",
                        "#######"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "flag_debug = False\n",
                        "# Initialize parameters\n",
                        "poses_open = np.zeros((0, 8))      # timestamp (utc), tx, ty, tz, qw, qx, qy, qz (open_loop)\n",
                        "poses_closed = np.zeros((0, 8)) # timestamp (utc), tx, ty, tz, qw, qx, qy, qz (closed_loop)\n",
                        "intrinsics = np.zeros((0, 6)) # fx, fy, cx, cy, width, height\n",
                        "gps_data = np.zeros((0, 6))   # timestamp, lat, lon, alt, speed, accuracy\n",
                        "img_save_idx = 0\n",
                        "# Load image\n",
                        "camera_label = \"camera-rgb\"; camera_stream_id = provider.get_stream_id_from_label(camera_label)\n",
                        "camera_num_data = provider.get_num_data(camera_stream_id)\n",
                        "print(f\"Stream ID (camera): {camera_stream_id} with {camera_num_data} data\")\n",
                        "# Load GPS\n",
                        "gps_label = \"gps\"; gps_stream_id = provider.get_stream_id_from_label(gps_label)\n",
                        "gps_num_data = provider.get_num_data(gps_stream_id)\n",
                        "print(f\"Stream ID (gps): {gps_stream_id} with {gps_num_data} data\")\n",
                        "\n",
                        "# Set a initial pose\n",
                        "init_pose_open, init_pose_closed = False, False\n",
                        "T_offset_open, T_offset_closed = SE3().from_matrix(np.eye(4, 4)), SE3().from_matrix(np.eye(4, 4))\n",
                        "\n",
                        "for index in range(0, camera_num_data):\n",
                        "# for index in range(100, 101):\n",
                        "    ##### Get image data\n",
                        "    img_data = provider.get_image_data_by_index(camera_stream_id, index)\n",
                        "    img_timestamp = img_data[1].capture_timestamp_ns\n",
                        "    # print(f\"Get image data at index {index} with timestamp {img_timestamp}\")\n",
                        "\n",
                        "    raw_calib = provider.get_device_calibration().get_camera_calib(camera_label)\n",
                        "    focal_length = raw_calib.get_focal_lengths()\n",
                        "    principal_point = raw_calib.get_principal_point()\n",
                        "    image_size = raw_calib.get_image_size() # width, height\n",
                        "    \n",
                        "    ##### Option 1: use the raw image size\n",
                        "    # pinhole = calibration.get_linear_camera_calibration(\n",
                        "    #     image_size[0], image_size[1], focal_length[0], camera_label, raw_calib.get_transform_device_camera())\n",
                        "    ##### Option 2: use the high-resolution image size\n",
                        "    # pinhole = calibration.get_linear_camera_calibration(\n",
                        "    #     1024, 2048, focal_length[0] * (2048 / image_size[0]), camera_label, raw_calib.get_transform_device_camera()) # height, width\n",
                        "    ##### Option 3: use the specific image size\n",
                        "    pinhole = calibration.get_linear_camera_calibration(\n",
                        "        576, 1024, focal_length[0] * (1024 / image_size[0]), camera_label, raw_calib.get_transform_device_camera()) # height, width\n",
                        "    raw_image = img_data[0].to_numpy_array()\n",
                        "    undistorted_image = calibration.distort_by_calibration(raw_image, pinhole, raw_calib)\n",
                        "    \n",
                        "    rotated_image = np.rot90(undistorted_image, k=3)\n",
                        "    pinhole_cw90 = calibration.rotate_camera_calib_cw90deg(pinhole)\n",
                        "    focal_length = pinhole_cw90.get_focal_lengths()\n",
                        "    principal_point = pinhole_cw90.get_principal_point()\n",
                        "    image_size = pinhole_cw90.get_image_size()\n",
                        "\n",
                        "    if flag_debug:\n",
                        "        plt.figure(figsize=(15,5))\n",
                        "        plt.subplot(1, 3, 1)\n",
                        "        plt.imshow(raw_image, cmap='gray', vmin=0, vmax=255)\n",
                        "        plt.title(\"Raw image\")\n",
                        "        plt.axis('off')\n",
                        "        plt.subplot(1, 3, 2)\n",
                        "        plt.imshow(undistorted_image, cmap='gray', vmin=0, vmax=255)\n",
                        "        plt.title(\"Undistorted image\")\n",
                        "        plt.axis('off')\n",
                        "        plt.subplot(1, 3, 3)\n",
                        "        plt.imshow(rotated_image, cmap='gray', vmin=0, vmax=255)\n",
                        "        plt.title(\"Rotated image\")\n",
                        "        plt.axis('off')\n",
                        "        plt.show()        \n",
                        "\n",
                        "    ##### Get pose data (open loop and closed loop)\n",
                        "    pose_info_open = get_nearest_pose(open_loop_traj, img_timestamp)\n",
                        "    pose_info_closed = get_nearest_pose(closed_loop_traj, img_timestamp)\n",
                        "    if pose_info_open and pose_info_closed:\n",
                        "        ##### Closed loop trajectory\n",
                        "        T_world_device = pose_info_closed.transform_world_device\n",
                        "        T_device_rgb_camera = pinhole_cw90.get_transform_device_camera()\n",
                        "        T_world_rgb_camera = T_world_device @ T_device_rgb_camera\n",
                        "        vec = T_world_rgb_camera.to_quat_and_translation()\n",
                        "        quat_wxyz, trans = vec[0, :4], vec[0, 4:]\n",
                        "        pose = np.array([pose_info_closed.utc_timestamp.total_seconds(), \n",
                        "                         trans[0], trans[1], trans[2], \n",
                        "                         quat_wxyz[1], quat_wxyz[2], quat_wxyz[3], quat_wxyz[0]])\n",
                        "        poses_closed = np.vstack((poses_closed, pose))\n",
                        "\n",
                        "        ##### Open loop trajectory\n",
                        "        T_world_device = pose_info_open.transform_odometry_device\n",
                        "        T_device_rgb_camera = pinhole_cw90.get_transform_device_camera()\n",
                        "        T_world_rgb_camera = T_world_device @ T_device_rgb_camera\n",
                        "        vec = T_world_rgb_camera.to_quat_and_translation()\n",
                        "        quat_wxyz, trans = vec[0, :4], vec[0, 4:]\n",
                        "        pose = np.array([pose_info_open.utc_timestamp.total_seconds(), \n",
                        "                         trans[0], trans[1], trans[2], \n",
                        "                         quat_wxyz[1], quat_wxyz[2], quat_wxyz[3], quat_wxyz[0]])\n",
                        "        poses_open = np.vstack((poses_open, pose))\n",
                        "\n",
                        "        ##### Get GPS data\n",
                        "        data = provider.get_gps_data_by_time_ns(gps_stream_id, img_timestamp, TimeDomain.DEVICE_TIME)\n",
                        "        if data.accuracy > 1e3 or data.accuracy < 1e-9:\n",
                        "            # Not valid GPS data\n",
                        "            vec = np.array([data.utc_time_ms / 1e3, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
                        "        else:\n",
                        "            vec = np.array([data.utc_time_ms / 1e3, data.latitude, data.longitude, data.altitude, data.speed, data.accuracy])\n",
                        "        if gps_data.shape[0] == 0 or np.abs(gps_data[-1, 0] - vec[0]) > 1e-6:\n",
                        "            gps_data = np.vstack((gps_data, vec))\n",
                        "\n",
                        "        ##### Intrinsics and Image\n",
                        "        intrinsic = np.array([focal_length[0], focal_length[1], \n",
                        "                              principal_point[0], principal_point[1], \n",
                        "                              image_size[0], image_size[1]])\n",
                        "        intrinsics = np.vstack((intrinsics, intrinsic))\n",
                        "        \n",
                        "        processed_img = reduce_image_domain_gap(rotated_image, domain_unified_flag=False)\n",
                        "        image_pil = Image.fromarray(processed_img.astype(np.uint8))\n",
                        "        image_pil.save(os.path.join(out_dir, \"seq\", f\"{img_save_idx:06d}.color.jpg\"))\n",
                        "        if img_save_idx % 100 == 0: print(f\"Save image {img_save_idx:06d}.color.jpg\")\n",
                        "        img_save_idx += 1\n",
                        "\n",
                        "np.savetxt(os.path.join(out_dir, \"poses_open_loop.txt\"), poses_open, fmt='%.9f')\n",
                        "np.savetxt(os.path.join(out_dir, \"poses_closed_loop.txt\"), poses_closed, fmt='%.9f')\n",
                        "np.savetxt(os.path.join(out_dir, \"intrinsics.txt\"), intrinsics, fmt='%.6f ' * 4 + '%d %d')\n",
                        "np.savetxt(os.path.join(out_dir, \"gps_data.txt\"), gps_data, fmt='%.6f')"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": [
                        "### Visualize Poses"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
                        "\n",
                        "axes[0].plot(poses_closed[:, 1], poses_closed[:, 2], '-')\n",
                        "axes[0].set_title('X-Y Curve Closed')\n",
                        "axes[0].set_xlabel('X')\n",
                        "axes[0].set_ylabel('Y')\n",
                        "axes[0].axis('equal')\n",
                        "axes[0].grid(True)\n",
                        "\n",
                        "axes[1].plot(poses_open[:, 1], poses_open[:, 2], '-')\n",
                        "axes[1].set_title('X-Y Curve Open')\n",
                        "axes[1].set_xlabel('X')\n",
                        "axes[1].set_ylabel('Y')\n",
                        "axes[1].axis('equal')\n",
                        "axes[1].grid(True)\n",
                        "\n",
                        "axes[2].plot(gps_data[:, 1], gps_data[:, 2], '-')\n",
                        "axes[2].set_title('GPS Curve')\n",
                        "axes[2].set_xlabel('Lat')\n",
                        "axes[2].set_ylabel('Lont')\n",
                        "axes[2].axis('equal')\n",
                        "axes[2].grid(True)\n",
                        "\n",
                        "plt.show()"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "projectaria",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.8.19"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
